{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Likhithavandanachaluvadi/FMML_LABS_23B21A4514/blob/main/FMML_Module_2_project_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module 2: Appreciating, Interpreting and Visualizing Data\n",
        "## Project\n",
        "\n",
        "```\n",
        "Coordinator: Aswin Jose\n",
        "```\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "R976BTHqth_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "PjKikpD7uCnb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we wil be performing a simple Exploratory Data Anaysis for this project. We will use the methods we learned in the tutorials to have a basic understanding of the dataset. So first we will start with the heart dataset available from kaggle. the infomration about the columns of the dataset is given below:    \n",
        "-age    \n",
        "-sex    \n",
        "-chest pain type (4 values)    \n",
        "-resting blood pressure    \n",
        "-serum cholestoral in mg/dl    \n",
        "-fasting blood sugar > 120 mg/dl    \n",
        "-resting electrocardiographic results (values 0,1,2)    \n",
        "-maximum heart rate achieved    \n",
        "-exercise induced angina   \n",
        "-oldpeak = ST depression induced by exercise relative to rest    \n",
        "-the slope of the peak exercise ST segment    \n",
        "-number of major vessels (0-3) colored by flourosopy    \n",
        "-:thal: 0 = normal; 1 = fixed defect; 2 = reversable defect    "
      ],
      "metadata": {
        "id": "Ep9v4Rj1rDaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill in the portions that says \"to do\""
      ],
      "metadata": {
        "id": "GVPNEAfBrs7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded1 = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "I9sX_JSdtpsH",
        "outputId": "df49f643-5d4a-4e45-a9da-de2e45791f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9a6ad30b-70d7-43cc-afc8-a34491021f6b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9a6ad30b-70d7-43cc-afc8-a34491021f6b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"heart.csv\")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "7CUciJW-t-aG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "j3fHpCWfuWSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns\n"
      ],
      "metadata": {
        "id": "DuxMngbivcdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preparation"
      ],
      "metadata": {
        "id": "N1OCngCVr5H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## we will be comparing rest of the parameters/columns present in the data with respect to precence or absece of heart disease\n",
        "data['target'] = data.target.replace({1: \"Disease\", 0: \"No_disease\"})\n",
        "data['sex'] = data.sex.replace({1: \"Male\", 0: \"Female\"})\n",
        "data['cp'] = data.cp.replace({1: \"typical_angina\",\n",
        "                          2: \"atypical_angina\",\n",
        "                          3:\"non-anginal pain\",\n",
        "                          4: \"asymtomatic\"})\n",
        "data['exang'] = data.exang.replace({1: \"Yes\", 0: \"No\"})\n",
        "data['slope'] = data.cp.replace({1: \"upsloping\",\n",
        "                          2: \"flat\",\n",
        "                          3:\"downsloping\"})\n",
        "data['thal'] = data.thal.replace({1: \"fixed_defect\", 2: \"reversable_defect\", 3:\"normal\"})"
      ],
      "metadata": {
        "id": "fRHrjko7xIwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "wl5oM9BZ2XVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, lets look at the difference in the number of samples with and without disease using a barplot."
      ],
      "metadata": {
        "id": "RKjU-NUW3op-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(data['target'].value_counts())\n",
        "plt.title('Heart Disease Classes')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9H3aQvCe2prB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## we can plot the same barplots usng the pandas inbuilt plotting functions.\n",
        "data['target'].value_counts().plot(kind='bar').set_title('Heart Disease Classes')"
      ],
      "metadata": {
        "id": "UpL7yRHR2ZA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Now plot a barplot indicating the the sex of the participants involved in the study, use whatever method of ploting comfortable for you\n",
        "## to do"
      ],
      "metadata": {
        "id": "J3pWoE-j282Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## pie charts can also be used to show the same infomation in a different manner\n",
        "plt.pie(data['target'].value_counts(), labels=[\"Disease\", \"No disease\"], autopct='%1.1f%%')\n",
        "plt.title('Target Labels')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6lzeMeXx6Ddl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# next we will plot the counts of all the non-continous features present in the dataset.\n",
        "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(17,10))\n",
        "cat_feat = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "\n",
        "for idx, feature in enumerate(cat_feat):\n",
        "    ax = axes[int(idx/3), idx%3]\n",
        "    sns.barplot(data[feature].value_counts(), ax=ax)"
      ],
      "metadata": {
        "id": "lhrwKDM62l67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##  now lets play with 2 vaiables in dataset. Lets see if chest pain translates to the presence of desease in most cases...\n",
        "sns.countplot(x='cp', hue='target', data=data, palette='rainbow').set_title('Disease classes according to Chest Pain')"
      ],
      "metadata": {
        "id": "5MNCxVhQ4x30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now lets visualise count of all vairables w.r.t the presence of disease togather:\n",
        "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(17,10))\n",
        "cat_feat = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "\n",
        "for idx, feature in enumerate(cat_feat):\n",
        "    ax = axes[int(idx/3), idx%3]\n",
        "    ## to do\n"
      ],
      "metadata": {
        "id": "smGhn01t5bqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualising the distribution of the continous variables"
      ],
      "metadata": {
        "id": "V0CiDMIK6pCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## pair plots can automoaticaly be used to viwe the pairwise relationship between all the  feature that we selected\n",
        "continous_features = ['age', 'chol', 'thalach', 'oldpeak','trestbps']\n",
        "sns.pairplot(data[continous_features + ['target']], hue='target')"
      ],
      "metadata": {
        "id": "6KnGCZz632hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now lets try to understand the relationship between age and chol in each of the target based on sex.\n",
        "sns.lmplot(x=\"age\", y=\"chol\", hue=\"sex\", col=\"target\",\n",
        "           palette=\"Set1\",\n",
        "           data=data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DtjSCsgl6vV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_data = data[continous_features]\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr_matrix = numeric_data.corr()\n",
        "sns.heatmap(corr_matrix, annot=True)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ywPbmTHx8Rqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, len(continous_features), figsize=(25, 4), sharex=False, sharey=False)\n",
        "\n",
        "for idx, feature in enumerate(continous_features):\n",
        "    sns.boxplot(x='target', y=feature, data=data, ax=axes[idx])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nOQvj2UT-4Wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot the cumulative variace of pca for all the possibel pronviopal components\n",
        "## to do\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "pca = PCA()\n",
        "pca.fit(numeric_data)\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Cumulative explained variance')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QLy3U9yOAAa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=2)\n",
        "pca.fit(numeric_data)\n",
        "pca_data = pca.transform(numeric_data)\n",
        "\n",
        "# Create a DataFrame with the principal components and target labels\n",
        "pca_df = pd.DataFrame({\n",
        "    \"pca_1\": pca_data[:, 0],\n",
        "    \"pca_2\": pca_data[:, 1],\n",
        "    \"target\": data[\"target\"]\n",
        "})\n",
        "\n",
        "# Visualize the PCA results with a scatter plot\n",
        "sns.scatterplot(x=\"pca_1\", y=\"pca_2\", hue=\"target\", data=pca_df)\n",
        "plt.title(\"PCA Visualization of Heart Disease Data\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9kb_TztC9hqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Initialize and fit the TSNE model\n",
        "tsne = TSNE(n_components=2)\n",
        "tsne_data = tsne.fit_transform(numeric_data)\n",
        "\n",
        "# Create a DataFrame with the TSNE components and target labels\n",
        "tsne_df = pd.DataFrame({\n",
        "    \"tsne_1\": tsne_data[:, 0],\n",
        "    \"tsne_2\": tsne_data[:, 1],\n",
        "    \"target\": data[\"target\"]\n",
        "})\n",
        "\n",
        "# Visualize the TSNE results with a scatter plot\n",
        "sns.scatterplot(x=\"tsne_1\", y=\"tsne_2\", hue=\"target\", data=tsne_df)\n",
        "plt.title(\"TSNE Visualization of Heart Disease Data\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QDKt3GQIAMHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the plots above, answer the following questions:    \n",
        "1. What is the percentage of Samples with Disease?    \n",
        "2. what are the 3 continous features that shows a singnficanct statistical differnce in distribution with respect to the precence and absence of the disease?    \n",
        "3. Can we see a clear seperation in terms of the presence/absence of disease in the features obtained from pca and tsne plots?    \n",
        "4. What is the optimal number of principal components in our case?    \n",
        "5. what are the continous features with the highest correation with each other?"
      ],
      "metadata": {
        "id": "AoQ8InmSuetP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets move on to do the same analysis on the starbucks nutrition dataset. this dataset contains the nutrition information of starbucks drinks."
      ],
      "metadata": {
        "id": "w8hH8CAhv8tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upload2 = files.upload()"
      ],
      "metadata": {
        "id": "a_RrGpN1ApCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"star_nutri_expanded.csv\")"
      ],
      "metadata": {
        "id": "NImD-yk0fpmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "YXZJPk4Zf636"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cleaning and filling the missing values in the data"
      ],
      "metadata": {
        "id": "2JA9ZVyywXk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Caffeine (mg)'] = data['Caffeine (mg)'].replace('Varies', np.NaN).replace('varies', np.NaN)\n",
        "data['Caffeine (mg)'] = data['Caffeine (mg)'].astype(np.float64)\n",
        "data['Caffeine (mg)'] = data['Caffeine (mg)'].fillna(data['Caffeine (mg)'].mean())"
      ],
      "metadata": {
        "id": "VrE3QA0GgCTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Total Fat (g)'].unique()"
      ],
      "metadata": {
        "id": "0PNMhN2GiQ6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Total Fat (g)'] = data['Total Fat (g)'].replace('3 2', '3.2')"
      ],
      "metadata": {
        "id": "Suua5EkTiRxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "u-I6TsTLkiMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract columns with int and float types\n",
        "numeric_columns = data.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
        "\n",
        "# Print the numeric columns\n",
        "print(numeric_columns)\n"
      ],
      "metadata": {
        "id": "xPfMl26LknBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be analysing the dataset using the fact that weather the drink comes under the category tea or not"
      ],
      "metadata": {
        "id": "9FY9pzBNwete"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Beverage_category'].unique()"
      ],
      "metadata": {
        "id": "LVljNoJgg9Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Tea'] = data['Beverage_category'].apply(lambda x: 1 if x == 'TazoÂ® Tea Drinks' else 0)\n",
        "data = data.drop('Beverage_category', axis=1)"
      ],
      "metadata": {
        "id": "4UZ4Tk7whVEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##  one hot encoding of categorical features in data\n",
        "def onehot_encode(df, columns, prefixes):\n",
        "    df = df.copy()\n",
        "    for column, prefix in zip(columns, prefixes):\n",
        "        dummies = pd.get_dummies(df[column], prefix=prefix)\n",
        "        df = pd.concat([df, dummies], axis=1)\n",
        "        df = df.drop(column, axis=1)\n",
        "    return df"
      ],
      "metadata": {
        "id": "OZanK3hSi6sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = onehot_encode(\n",
        "    data,\n",
        "    columns=['Beverage', 'Beverage_prep'],\n",
        "    prefixes=['bev', 'bevp']\n",
        ")"
      ],
      "metadata": {
        "id": "PlZCj2rwi7us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = data.replace({True: 1, False: 0})\n"
      ],
      "metadata": {
        "id": "w7qKp8JMwysG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.applymap(lambda x: np.float64(str(x).replace('%', '')))"
      ],
      "metadata": {
        "id": "I-RIoXq6ig3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "J_BgqsKogWE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "iB5PmiPojj3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## to do\n",
        "\n",
        "# Create a pie chart of the 'Tea' column also write your observation form the plot\n",
        "\n"
      ],
      "metadata": {
        "id": "KxZYShn1hpYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## to do\n",
        "# perform pca on the data and plot the explained variace ratio, what is the optimal number of principal components in this case ?\n"
      ],
      "metadata": {
        "id": "HL2dDjYfh2L8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## to do\n",
        "# visualise the principal components, choose the number of principal components based on the above plot. What is you observation from the plot?\n"
      ],
      "metadata": {
        "id": "tNKX2JJVjwrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## to do\n",
        "# plot the first 2 components of tsne, whats you observation from the plot?\n"
      ],
      "metadata": {
        "id": "tgpIgiYdlVcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## to do\n",
        "# create a correlation matrix and plot the heatmap, whats your observation from the heatmap ?\n"
      ],
      "metadata": {
        "id": "cOWaPpnmj4OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## to do\n",
        "# make a boxplot of all the numeric columns of the dataset. Which column/columns can be the most potential indicator weather its a tea or a non tea drink?\n"
      ],
      "metadata": {
        "id": "VJMRR3yqkNb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To enhance the clarity and professionalism of the provided text, consider the following refined version: In the process of conducting a preliminary Exploratory Data Analysis (EDA), we have utilized various techniques to gain insights into the datasets under consideration. It's important to note that our analysis extends beyond the initial visualizations, embracing a multitude of methods to thoroughly understand the data.\n",
        "Among the array of tools available for EDA, one particularly easy solution is the use of the pandas profiling library. This tool significantly simplifies the process of exploring the fundamental distribution of data within a dataset. By generating detailed profile reports, pandas profiling provides a comprehensive overview of the dataset's characteristics, including but not limited to, the distribution of variables, presence of missing values, and potential correlations between variables.\n",
        "Furthermore, we are utilizing Google Colab notebooks, the integration of AI tools offers an additional avenue for data visualization and analysis. These tools can automatically generate insightful plots and statistics, further enriching the data exploration process."
      ],
      "metadata": {
        "id": "_yRYeXpfzY7O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iDevVx8Bo8lN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}